{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Programmin in Scala \n",
    "\n",
    "## Instructors: Viktor Kincak and Aleksander Prokopek\n",
    "\n",
    "# Week 1: Summary\n",
    "\n",
    "**Author:** [Ehsan M.Kermani](https://ca.linkedin.com/in/ehsanmkermani)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel vs. Concurrent\n",
    "\n",
    "## Parallel: uses parallel hardware to execute computation more quickly. Efficiency is its main concern.\n",
    "\n",
    "* Divisions into subproblems\n",
    "* Optional use of parallel hardware\n",
    "* Usage: Numerical, simulation and Big Data applications\n",
    "* Concerns with Speed-up\n",
    "\n",
    "## Concurrent: may or may not use multiple executions at the same time. Improves modularity, responsiveness and maintainability.\n",
    "\n",
    "* When can an execution start?\n",
    "* How can information exchange occur?\n",
    "* How to manage access to shared resources?\n",
    "* Usage: Web servers, user interface and databases\n",
    "* Concers with convenience\n",
    "\n",
    "# Parallelism Granularity\n",
    "\n",
    "* Bit-level: processing multiple bits of data in parallel --> hardware\n",
    "* Structure-level: excuting different instructions from the same instruction stream in parallel --> hardware\n",
    "* Task-level: excuting separate instruction streams in parallel --> software [Course Focus]\n",
    "\n",
    "## NOTE: Course focus: programming multi-cores and SMPs (symmetric multi-processors) with shared memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Parallelism on JVM\n",
    "\n",
    "## Process: An instance of a program executing in OS \n",
    "\n",
    "* OS assignes resources, such as execution time on cpu, memory address space, etc.\n",
    "* Each process has a **unique** process id\n",
    "* Process is the most coarsed-grained unit in shared memory system\n",
    "* Multitasking: dividing different processes into (consecutive) time slices for execution\n",
    "* Each process is **isolated** from other processes, i.e. two different processes cannot access each other memory\n",
    "\n",
    "## Thread: \n",
    "\n",
    "* Each process can contain multiple independent concurrency units called thread\n",
    "* Threads can be started from the same program and can share the same memory address\n",
    "* Each thread has a program counter (i.e. position of the current method) and program stack (i.e. sequence of memory containing methods being executed)\n",
    "* Different threads cannot modify each other program stacks\n",
    "* Communication happens by modifying heap-memory\n",
    "\n",
    "### Create and Start Threads:\n",
    "\n",
    "* Each **JVM process** starts with a **main thread** (sequential only uses main method to run, parallel must start\n",
    "additional threads\n",
    "* Starting additional thread:\n",
    "\n",
    "    1. Define a *Thread* subclass\n",
    "    2. Instatiate a new *Thread* object (tracking the execution)\n",
    "    3. Call *start* on the *Thread* object\n",
    "    \n",
    "* A custom Thread subclass can be used to start multiple threads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass \u001b[36mHelloThread\u001b[0m\n",
       "\u001b[36mt\u001b[0m: \u001b[32m$user\u001b[0m.\u001b[32mHelloThread\u001b[0m = Thread[Thread-14,5,]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "/** HelloThread **/\n",
    "\n",
    "/* 1. Define */\n",
    "class HelloThread extends Thread {\n",
    "    override def run() = {\n",
    "        println(\"Hello, world222\")\n",
    "    }\n",
    "}\n",
    "\n",
    "/*2. Instantiate*/\n",
    "val t = new HelloThread\n",
    "\n",
    "/*3. Start*/\n",
    "t.start()\n",
    "\n",
    "/** When main thread calls join, it blocks its execution until t completes.\n",
    "    Then after t completes, main thread continues\n",
    "**/\n",
    "t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threads can overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "world\n",
      "Hello\n",
      "world\n",
      "\n",
      "\n",
      "Hello\n",
      "world\n",
      "Hello\n",
      "world\n",
      "\n",
      "\n",
      "Hello\n",
      "world\n",
      "Hello\n",
      "world\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass \u001b[36mHelloThread\u001b[0m\n",
       "defined \u001b[32mfunction \u001b[36mmain\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class HelloThread extends Thread {\n",
    "    override def run() = {\n",
    "        println(\"Hello\")\n",
    "        println(\"world\")\n",
    "    }\n",
    "}\n",
    "\n",
    "def main() = {\n",
    "    val t = new HelloThread\n",
    "    val s = new HelloThread\n",
    "    t.start()\n",
    "    s.start()\n",
    "    t.join()\n",
    "    s.join()\n",
    "    println(\"\\n\")\n",
    "}\n",
    "\n",
    "/*execute as many time as necessary to see the effect*/\n",
    "main()\n",
    "main()\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure a sequence of statements in a specific thread executes at once\n",
    "\n",
    "## Atomicity:\n",
    "\n",
    "* An operation is **atomic** if it appears *as if* it occured instantaneously from the view point of other threads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/*NOT atomic*/\n",
    "private var uidCount = 0L\n",
    "def getUniqueId(): Long = {\n",
    "    uidCount = uidCount + 1\n",
    "    uidCount\n",
    "}\n",
    "\n",
    "def startThread() = {\n",
    "    val t = new Thread {\n",
    "        override def run() = {\n",
    "            val uids = for(i <- 1 until 10) yield getUniqueId()\n",
    "            println(uids)\n",
    "        }\n",
    "    }\n",
    "    t.start()\n",
    "    t\n",
    "}\n",
    "\n",
    "startThread()\n",
    "startThread()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the results are not disjoint from each other! because `getUniqueId` method is **NOT** atomic and separate `uidCount` can *interleave* arbitrarily when executed on different threads "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronized block: to enforce atomicity\n",
    "\n",
    "* A code block after a `synchronized` call on an *object* x, is **never** executed by two different threads at the same time\n",
    "\n",
    "* JVM ensures this by storing a *monitor* (which is a resource) in each object\n",
    "* At most *one thread* can own a monitor at a particular time\n",
    "* A sybchronized block is an example of a *synchronized primitive* (allowing different threads to exchange info)\n",
    "\n",
    "NOTE: *synchronized method* **must** be invoked on an instance of some object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "private val x = new AnyRef {} /* just an object to invoke synchronized on*/\n",
    "private var uidCount = 0L\n",
    "/* make getUniqueId atomic*/\n",
    "def getUniqueId(): Long = x.synchronized {\n",
    "    uidCount = uidCount + 1\n",
    "    uidCount\n",
    "}\n",
    "\n",
    "def startThread() = {\n",
    "    val t = new Thread {\n",
    "        override def run() = {\n",
    "            val uids = for(i <- 1 until 10) yield getUniqueId()\n",
    "            println(uids)\n",
    "        }\n",
    "    }\n",
    "    t.start()\n",
    "    t\n",
    "}\n",
    "\n",
    "startThread()\n",
    "startThread()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose (nest) synchronized blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/** Does NOT terminate: it is a Deadlock **/\n",
    "\n",
    "/**\n",
    "    Don't want to have a global synchronized block as it becomes the bottleneck in parallel execution\n",
    "**/\n",
    "class Account(private var amount: Int = 0) {\n",
    "    \n",
    "    def transfer(target: Account, n: Int) = \n",
    "        this.synchronized { /* first monitor this*/\n",
    "            target.synchronized { /* second monitor both*/\n",
    "                this.amount -= n\n",
    "                target.amount += n \n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "def startThread(a: Account, b: Account, n: Int) = {\n",
    "    val t = new Thread {\n",
    "        override def run() = {\n",
    "            for(i <- 1 until n) {\n",
    "                a.transfer(b, 1)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    t.start()\n",
    "    t\n",
    "}\n",
    "\n",
    "val a1 = new Account(100)\n",
    "val a2 = new Account(200)\n",
    "\n",
    "val t = startThread(a1, a2, 50)\n",
    "val s = startThread(a2, a1, 50)\n",
    "\n",
    "t.join()\n",
    "s.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above doesn't terminate, because the main thread program is **blocked** waiting for t, s to complete and in fact, the threads t, s never complete and just **waiting** for each other to finish (Deadlock)\n",
    "\n",
    "## Deadlock: A senario where two or more threads compete for *resources* (such as monitor ownership)  and wait for each other to finish *without releasing* the already aquired resources\n",
    "\n",
    "## Resolving Deadlock:\n",
    "\n",
    "* One approach is to define ordering on resources and aquire them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target amount before transfer: 200\n",
      "target amount before transfer: 100\n",
      "target amount after transfer: 100\n",
      "target amount after transfer: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass \u001b[36mAccount\u001b[0m\n",
       "defined \u001b[32mfunction \u001b[36mstartThread\u001b[0m\n",
       "\u001b[36ma1\u001b[0m: \u001b[32m$user\u001b[0m.\u001b[32mAccount\u001b[0m = 100\n",
       "\u001b[36ma2\u001b[0m: \u001b[32m$user\u001b[0m.\u001b[32mAccount\u001b[0m = 200\n",
       "\u001b[36mt\u001b[0m: \u001b[32mThread\u001b[0m = Thread[Thread-13,5,]\n",
       "\u001b[36ms\u001b[0m: \u001b[32mThread\u001b[0m = Thread[Thread-14,5,]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Account(var amount: Int = 0) {\n",
    "    \n",
    "    private var uidCount = 0L\n",
    "    private def getUniqueId(): Long =  this.synchronized {\n",
    "    uidCount = uidCount + 1\n",
    "    uidCount\n",
    "    }\n",
    "    \n",
    "    private def lockAndTransfer(target: Account, n: Int) = {\n",
    "        this.synchronized {\n",
    "            target.synchronized {\n",
    "                this.amount -= n\n",
    "                target.amount += n\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def transfer(target: Account, n: Int) = \n",
    "        if (this.getUniqueId() < target.getUniqueId()) { \n",
    "            lockAndTransfer(target, n)\n",
    "            println(s\"target amount after transfer: $target\")\n",
    "        }\n",
    "        else {\n",
    "            target.lockAndTransfer(this, -n)\n",
    "            println(s\"target amount after transfer: $target\")\n",
    "        }\n",
    "    \n",
    "    override def toString() = amount.toString()\n",
    "}\n",
    "\n",
    "def startThread(a: Account, b: Account, n: Int) = {\n",
    "    val t = new Thread {\n",
    "        override def run() = {\n",
    "            println(s\"target amount before transfer: $b\")\n",
    "            a.transfer(b, n)\n",
    "        }\n",
    "    }\n",
    "    t.start()\n",
    "    t\n",
    "}\n",
    "\n",
    "\n",
    "val a1 = new Account(100)\n",
    "val a2 = new Account(200)\n",
    "\n",
    "val t = startThread(a1, a2, 50)\n",
    "val s = startThread(a2, a1, 50)\n",
    "\n",
    "t.join()\n",
    "s.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory model:\n",
    "\n",
    "Specific set of rules describing how threads can interact when accessing share memory such as\n",
    "\n",
    "* Two threads writing to separate locations in memory don't need synchronization\n",
    "* A thread $X$ that calls `join` on other thread $Y$ is *guaranteed to observe* all the writes by thread $Y$ after `join` returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Construct:\n",
    "\n",
    "If we have a parallel construct `parallel` taking to functions and executing them in parallel, we would expect to \n",
    "have the following signature:\n",
    "\n",
    "`def paralle[A, B](taskA: => A, taskB: => B): (A, B) = {...}`\n",
    "\n",
    "It's crucial `taskA, taskB` are evaluated by *name*, otherwise, it'd just be the same as sequantial executions!\n",
    "\n",
    "The *minimum* time of parallel execution of `taskA, taskB` is the *maximum* time of separate executions of `taskA, taskB`.\n",
    "\n",
    "NOTE: In parallel applications, be aware of bottlenecks, such as, memory, network band-width (in cluster computing), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Flexible Construct with Task:\n",
    "\n",
    "* `t = task(e)` is a *task* which starts computation in background\n",
    "* Current (other) computation proceeds in parallel with t\n",
    "* `t.join()` obtains the result of the computation\n",
    "* `t.join()` *blocks* and waits until the result is computed\n",
    "* Subsequent `t.join()` calls quickly return the same results\n",
    "\n",
    "### Minimal interface:\n",
    "\n",
    "```scala\n",
    "trait Task[A] {\n",
    "    def join(): A\n",
    "}\n",
    "def task(c: => A): Task[A]\n",
    "```\n",
    "\n",
    "where `task` and `join` establish **maps** between *computations* and *tasks*. \n",
    "\n",
    "**Identity:** `task(e).join()` equals evaluating `e.`\n",
    "\n",
    "Omit `join` by implicit conversion: `implicit def getJoin[T](x: Task[T]) = x.join()`\n",
    "\n",
    "Now, we can use `task` to define `parallel` construct as follows;\n",
    "\n",
    "```scala\n",
    "def parallel[A, B](cA: => A, cB: => B): (A, B) = {\n",
    "     val t: Task[A] = task(cA)\n",
    "     val s: A = cB /* computes cB directly*/\n",
    "     (t.join(), s)\n",
    " }\n",
    "```\n",
    "\n",
    "However, if we'd called `join()` earlier in when computing `val t = task(cA).join()`, that would indeed result in *sequential* computation, not parallel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Time Analysis:\n",
    "\n",
    "* Sequential `reduce()` (contains, `sum(), max(), min()`, etc.) is of $O(n)$\n",
    "* Parallel `reduce()` is of $O(\\log n)$, given enough resources and in general, $c_1\\log n + c_2\\dfrac{n}{p} + c_3 ,$ given $p$ processors\n",
    "\n",
    "### Definition:\n",
    "\n",
    "* W(e): time for sequential execution of e \n",
    "* D(e): time for parallel execution of e as if there're unlimited number of resources\n",
    "\n",
    "Then\n",
    "\n",
    "* $W(\\text{parallel}(e_1, e_2)) = W(e_1) + W(e_2) + c$ some constant $c$\n",
    "* $D(\\text{parallel}(e_1, e_2)) = \\max(D(e_1), D(e_2)) + c'$\n",
    "\n",
    "and for function call $f(e_1, \\cdots, e_n)$ (assuming arguments are all call-by-value!)\n",
    "\n",
    "* $W(f(e_1, \\cdots, e_n)) = W(e_1) + \\cdots + W(e_n) + W(f)(v_1, \\cdots, v_n)$\n",
    "* $D(f(e_1, \\cdots, e_n)) = D(e_1) + \\cdots + D(e_n) + D(f)(v_1, \\cdots, v_n)$\n",
    "\n",
    "where $v_i$ is the value of $e_i.$ \n",
    "\n",
    "Assuming constant communication time, given $p$ processors, we'd have:\n",
    "\n",
    "$$D(e) \\leq D(e) + \\dfrac{W(e)}{p} \\leq W(e)$$\n",
    "\n",
    "* If $p$ is constant and input $e$ grows, then $D(e) + \\dfrac{W(e)}{p} \\rightarrow W(e)$ sequential\n",
    "* If $e$ is constant but $p$ grows, then $D(e) + \\dfrac{W(e)}{p} \\rightarrow D(e)$\n",
    "\n",
    "## Amdahl's Law:\n",
    "\n",
    "If $f$ is the sequential fraction of a computation that cannot be made faster, and we can make the remain $1-f$ fraction, $p$ times faster, the **speedup** will be *bounded* by\n",
    "\n",
    "$$\\dfrac{1}{f + \\left(\\dfrac{1-f}{p} \\right)}$$\n",
    "\n",
    "Note: Amdahl's law is based on fixed input size. More realist bound is given by [Gustafson's law](https://en.wikipedia.org/wiki/Gustafson%27s_law)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Factors in Benchmarking:\n",
    "\n",
    "* Processors speed\n",
    "* Number of processors\n",
    "* Memory latency and throughput\n",
    "* Cache behavior\n",
    "* Runtime behavior (e.g. garbage collection, JIT compilation, etc.)\n",
    "\n",
    "For more details, see [What Every Programmer Should Know About Memory](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf)\n",
    "\n",
    "For measurement methodologies, see [Statistically Rigorous Java Performance Evaluation](https://buytaert.net/files/oopsla07-georges.pdf)\n",
    "\n",
    "### ScalaMeter: benchmarking and performance regression testing framework on JVM\n",
    "\n",
    "Add dependency by to sbt:\n",
    "\n",
    "`libraryDependencies += \"com.storm-enroute\" %% \"scalameter-core\" % \"0.6\"`\n",
    "\n",
    "then\n",
    "\n",
    "`import org.scalameter._`\n",
    "\n",
    "`val time = measure {\n",
    "    (0 until 1000000).toArray\n",
    "}`\n",
    "\n",
    "and to warm-up JVM\n",
    "\n",
    "`\n",
    "val time = withWarmer(new Warmer.Default) measure {\n",
    "    (0 until 1000000).toArray\n",
    "}\n",
    "`\n",
    "or can add more configuration. For more details, see [ScalaMeter](https://scalameter.github.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
